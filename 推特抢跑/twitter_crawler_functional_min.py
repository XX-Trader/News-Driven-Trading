#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Twitter çˆ¬å–æœ€å°æµç¨‹ï¼ˆè„šæœ¬ç‰ˆï¼Œä½¿ç”¨ matplotlib é¢„è§ˆå›¾ç‰‡ï¼‰
- æµç¨‹ï¼šé…ç½® â†’ è·å– â†’ è§£æ â†’ å­˜å‚¨(JSON/CSV) + åª’ä½“ä¸‹è½½ä¸ matplotlib é¢„è§ˆ â†’ AI æ–‡æœ¬åˆ†æï¼ˆPoe OpenAI å…¼å®¹ï¼‰
- è¯´æ˜ï¼šæœ¬è„šæœ¬å¯ç›´æ¥ç”¨ `python twitter_crawler_functional_min.py` è¿è¡Œï¼›æ— éœ€ Notebook è§†å›¾ã€‚
"""

import os
import json
import time
import csv
from datetime import datetime
from typing import List, Dict, Any

import requests

# ä»…ä½¿ç”¨ matplotlib æ˜¾ç¤ºå›¾ç‰‡ï¼ˆå¯é€‰ï¼‰
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

# -----------------------
# æ˜¾ç¤ºä¸å­—ä½“åˆå§‹åŒ–
# -----------------------
matplotlib.rcParams.update({
    "figure.figsize": (6, 4),
    "figure.dpi": 120,
    "savefig.dpi": 120,
    "axes.unicode_minus": False,  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜
})
# ä¸­æ–‡å­—ä½“å›é€€ï¼ˆè‹¥æ— ä¼šè‡ªåŠ¨å›é€€è‹±æ–‡ï¼Œä¸æŠ¥é”™ï¼‰
for _f in ["SimHei", "Microsoft YaHei", "Arial Unicode MS"]:
    try:
        matplotlib.rcParams["font.sans-serif"] = [_f]
        break
    except Exception:
        pass

# -----------------------
# é…ç½®ï¼ˆæŒ‰éœ€ä¿®æ”¹ï¼‰
# -----------------------
API_KEY = "new1_58fe956453e744e4844728c68ba187d4"  # Twitteræ¥å£å¯†é’¥ï¼Œæ”¾åœ¨è¯·æ±‚å¤´X-API-Keyä¸­ï¼ˆç¤ºä¾‹ï¼‰
API_URL = "https://api.twitterapi.io/twitter/user/last_tweets"  # ç”¨æˆ·æœ€è¿‘æ¨æ–‡API

TARGET_USER = "cz_binance"   # é»˜è®¤æŠ“å–ç”¨æˆ·ï¼ˆä¸å«@ï¼‰
TWEET_LIMIT = 1              # æ¯æ¬¡è¯·æ±‚æ¨æ–‡æ¡æ•°
REQUEST_INTERVAL_SEC = 5     # è¯·æ±‚é—´éš”ï¼ˆå›ºå®š5ç§’ï¼‰

MEDIA_DIR = os.path.join(os.path.dirname(__file__), "twitter_media")  # åª’ä½“æœ¬åœ°ç›®å½•

# Poe(OpenAIå…¼å®¹)é…ç½®ï¼ˆå¦‚éœ€ä½¿ç”¨ AI åˆ†æï¼‰
AI_API_KEY = "lUOtczZXbp6emUFgvqfZC7odtwGEhBdwmIAdTlpLHzs"  # ç¤ºä¾‹ Keyï¼ˆå»ºè®®æ”¹ä¸ºç¯å¢ƒå˜é‡ï¼‰
AI_BASE_URL = "https://api.poe.com/v1"
AI_MODEL = "gpt-5"

# æœ¬åœ°è°ƒè¯•æ•°æ®è·¯å¾„ï¼ˆå§‹ç»ˆæŒ‡å‘ latest.jsonï¼Œfetch åè¦†ç›–å†™å…¥ï¼‰
LOCAL_JSON_PATH = os.path.join(os.path.dirname(__file__), "twitter_media", "latest.json")

print("[INIT] é…ç½®ä¸æ˜¾ç¤ºåˆå§‹åŒ–å®Œæˆ")

# -----------------------
# å·¥å…·å‡½æ•°
# -----------------------
def ensure_media_dir(path: str = MEDIA_DIR) -> str:
    """ç¡®ä¿åª’ä½“ä¿å­˜ç›®å½•å­˜åœ¨ï¼Œè¿”å›ç»å¯¹è·¯å¾„ã€‚"""
    p = os.path.abspath(path)
    os.makedirs(p, exist_ok=True)
    return p


def download_file(url: str, local_path: str, timeout: int = 30) -> bool:
    """ä¸‹è½½å•ä¸ªåª’ä½“æ–‡ä»¶åˆ° local_pathï¼Œå¤±è´¥è¿”å› Falseã€‚"""
    try:
        r = requests.get(url, timeout=timeout, stream=True)
        r.raise_for_status()
        with open(local_path, "wb") as f:
            for c in r.iter_content(8192):
                if c:
                    f.write(c)
        return True
    except Exception as e:
        print("[WARN] åª’ä½“ä¸‹è½½å¤±è´¥:", e)
        return False


def load_local_json_strict(path: str) -> List[Dict]:
    """ä¸¥æ ¼ä»æœ¬åœ° JSON è¯»å–ï¼šåŸè®¾è®¡è¦æ±‚é¡¶å±‚ä¸º list[dict]ã€‚
    ä¸ºå¢å¼ºé²æ£’æ€§ï¼Œè¿™é‡Œåšå‘åå…¼å®¹ï¼š
    - è‹¥é¡¶å±‚ä¸º dictï¼Œä¼˜å…ˆå°è¯•æå– data/tweets/results/items ç­‰å¸¸è§æ•°ç»„é”®ï¼›
      è‹¥ä¸Šè¿°é”®ä¸å­˜åœ¨ä½†å­˜åœ¨å•æ¨æ–‡å¯¹è±¡ï¼Œåˆ™åŒ…è£…ä¸ºå•å…ƒç´ åˆ—è¡¨ã€‚
    - æœ€ç»ˆä»ä¿è¯è¿”å› List[Dict]ï¼Œå¦åˆ™æŠ›å‡º ValueErrorã€‚
    """
    with open(path, "r", encoding="utf-8") as f:
        data = json.load(f)

    # å·²æ˜¯æ ‡å‡† list[dict]
    if isinstance(data, list):
        for i, item in enumerate(data):
            if not isinstance(item, dict):
                snippet = str(item)
                if len(snippet) > 120:
                    snippet = snippet[:120] + "..."
                raise ValueError(f"æœ¬åœ°JSONç¬¬{i}é¡¹ä¸æ˜¯dictï¼Œå®é™…ç±»å‹={type(item)}ï¼Œç‰‡æ®µ={snippet}")
        return data

    # é¡¶å±‚æ˜¯ dictï¼Œåšå…¼å®¹å¤„ç†
    if isinstance(data, dict):
        # ä¼˜å…ˆæå–å¸¸è§æ•°ç»„å­—æ®µ
        for key in ("data", "tweets", "results", "items"):
            arr = data.get(key)
            if isinstance(arr, list):
                for i, item in enumerate(arr):
                    if not isinstance(item, dict):
                        snippet = str(item)
                        if len(snippet) > 120:
                            snippet = snippet[:120] + "..."
                        raise ValueError(f"æœ¬åœ°JSON.{key}[{i}] ä¸æ˜¯dictï¼Œå®é™…ç±»å‹={type(item)}ï¼Œç‰‡æ®µ={snippet}")
                return arr

        # è‹¥å­˜åœ¨æ˜ç¡®çš„å•æ¡æ¨æ–‡å¯¹è±¡ï¼ˆä¾‹å¦‚ id/text/url ç­‰ï¼‰ï¼Œåˆ™åŒ…ä¸€å±‚åˆ—è¡¨è¿”å›
        possible_tweet_like_keys = {"id", "text", "url", "twitterUrl", "createdAt", "author"}
        if any(k in data for k in possible_tweet_like_keys):
            return [data]

        # è‹¥å­˜åœ¨ pin_tweet / tweets ç»„åˆä½† tweets ä¸æ˜¯ listï¼ˆæç«¯åœºæ™¯ï¼‰ï¼Œå°è¯•å¿½ç•¥é list å€¼
        if "pin_tweet" in data and "tweets" in data and isinstance(data.get("tweets"), list):
            arr = data["tweets"]
            for i, item in enumerate(arr):
                if not isinstance(item, dict):
                    snippet = str(item)
                    if len(snippet) > 120:
                        snippet = snippet[:120] + "..."
                    raise ValueError(f"æœ¬åœ°JSON.tweets[{i}] ä¸æ˜¯dictï¼Œå®é™…ç±»å‹={type(item)}ï¼Œç‰‡æ®µ={snippet}")
            return arr

        raise ValueError(f"ä¸æ”¯æŒçš„æœ¬åœ°JSON(dict)å¸ƒå±€ï¼Œæœªæ‰¾åˆ°æ•°ç»„å­—æ®µ(data/tweets/results/items)ï¼Œæ–‡ä»¶={path}")

    raise ValueError(f"æœ¬åœ°JSONé¡¶å±‚å¿…é¡»æ˜¯æ•°ç»„(list)æˆ–å¯¹è±¡(dict)ï¼Œå½“å‰ç±»å‹={type(data)}ï¼Œæ–‡ä»¶={path}")


def fetch_last_tweets(username: str, count: int = TWEET_LIMIT) -> List[Dict]:
    """è°ƒç”¨ last_tweets æ¥å£è·å–åŸå§‹æ¨æ–‡åˆ—è¡¨ï¼Œä¸åšé‡è¯•ä¸å›é€€ã€‚"""
    params = {"userName": username.lstrip("@"), "count": count}
    headers = {"X-API-Key": API_KEY}
    try:
        resp = requests.get(API_URL, params=params, headers=headers, timeout=30)
    except Exception as e:
        print("[ERR ] è¯·æ±‚å¼‚å¸¸:", e)
        return []

    if resp.status_code != 200:
        print("[ERR ] è¯·æ±‚å¤±è´¥:", resp.status_code, resp.text[:200])
        return []
    try:
        print("[INFO] å“åº”:", resp.status_code, resp.text[:200])
        data = resp.json()
        # å…¼å®¹ä¸¤ç±»è¿”å›ï¼šdict åŒ…è£¹ æˆ– ç›´æ¥ list
        if isinstance(data, list):
            return data
        if isinstance(data, dict):
            return data.get("data") or data.get("tweets") or data.get("results") or []
        return []
    except Exception as e:
        print("[ERR ] JSONè§£æå¤±è´¥:", e, resp.text[:200])
        return []


def parse_tweets(raw: List[Dict]) -> List[Dict]:
    """å°†åŸå§‹æ¨æ–‡è®°å½•è§£æä¸ºç»“æ„åŒ–å­—æ®µï¼Œå¹¶æ”¶é›†åª’ä½“åˆ—è¡¨ï¼ˆentities å’Œ includesï¼‰ã€‚
    æ³¨æ„ï¼šæŒ‰ä½ çš„è¦æ±‚ï¼Œä¸åœ¨æ­¤åŠ å…¥ç±»å‹å®ˆå«ï¼Œä¾èµ– strict loader ç¡®ä¿ raw ä¸º List[Dict]ã€‚
    """
    out: List[Dict] = []
    for t in raw:
        media = []
        ents = t.get("entities", {})
        if isinstance(ents.get("media"), list):
            for m in ents["media"]:
                url = m.get("media_url") or m.get("url") or m.get("media_url_https")
                if url:
                    media.append({"id": m.get("id"), "type": m.get("type"), "url": url})

        inc = t.get("includes", {})
        if isinstance(inc.get("media"), list):
            for m in inc["media"]:
                url = m.get("url") or m.get("preview_image_url")
                if url:
                    media.append({"id": m.get("media_key") or m.get("id"), "type": m.get("type"), "url": url})

        out.append({
            "tweet_id": t.get("id"),
            "created_at": t.get("created_at"),
            "text": t.get("text", ""),
            "author": t.get("author_username") or t.get("author_id"),
            "permalink": t.get("url") or t.get("permalink"),
            "media": media,
        })
    return out


def save_json(path: str, data: List[Dict]) -> None:
    """å°†è§£æåçš„åˆ—è¡¨å†™å…¥ JSON æ–‡ä»¶ï¼ˆUTF-8ï¼Œå¸¦ç¼©è¿›ï¼‰ã€‚"""
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


def save_csv(path: str, rows: List[Dict]) -> None:
    """å°†æ ¸å¿ƒå­—æ®µå†™å…¥ CSVï¼Œé¿å…æ¢è¡Œä¸é€—å·å¹²æ‰°ã€‚"""
    with open(path, "w", newline="", encoding="utf-8") as f:
        w = csv.writer(f)
        w.writerow(["tweet_id", "created_at", "author", "text", "permalink", "media_count"])
        for r in rows:
            w.writerow([
                r["tweet_id"],
                r["created_at"],
                r["author"],
                (r.get("text") or "").replace("\n", " "),
                r["permalink"],
                len(r["media"]),
            ])


def _show_image(path: str) -> None:
    """ä½¿ç”¨ matplotlib æ˜¾ç¤ºæœ¬åœ°å›¾ç‰‡æ–‡ä»¶ã€‚"""
    try:
        img = mpimg.imread(path)
    except Exception as e:
        print("[WARN] æ‰“å¼€å›¾ç‰‡å¤±è´¥:", e, " ->", path)
        return
    plt.figure(figsize=(4, 4))
    plt.imshow(img)
    plt.axis("off")
    plt.tight_layout()
    plt.show()


def store_media_and_preview(rows: List[Dict], limit: int = 3) -> None:
    """ä¸‹è½½åª’ä½“åˆ°æœ¬åœ°å¹¶åœ¨è„šæœ¬ä¸­å¼¹å‡º matplotlib çª—å£é¢„è§ˆå‰è‹¥å¹²å¼ å›¾ç‰‡ã€‚"""
    ensured = ensure_media_dir()
    shown = 0
    for r in rows:
        for m in r["media"]:
            url = m["url"]
            ext = os.path.splitext(url.split("?")[0])[1] or ".jpg"
            fname = f"{r['tweet_id']}_{m.get('id','m')}{ext}"
            lp = os.path.join(ensured, fname)
            if download_file(url, lp) and ext.lower() in [".jpg", ".jpeg", ".png", ".gif"] and shown < limit:
                _show_image(lp)
                shown += 1


# -----------------------
# AI åˆ†æï¼ˆå¯é€‰ï¼‰
# -----------------------
def ai_analyze_text(text: str, hint: str = "") -> str:
    """è°ƒç”¨ Poe(OpenAIå…¼å®¹) æ¥å£åšç®€è¦åˆ†æï¼›å¦‚ç¯å¢ƒæ—  openaiï¼Œè¿”å›å ä½ç»“æœã€‚"""
    promot = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŠ å¯†è´§å¸äº¤æ˜“åˆ†æå¸ˆã€‚è¯·åˆ†æä»¥ä¸‹Twitteræ¨æ–‡å†…å®¹ï¼Œåˆ¤æ–­å…¶å¯¹äº¤æ˜“çš„å½±å“ã€‚

æ¨æ–‡å†…å®¹ï¼š{text}

åˆ†æè¦æ±‚ï¼š
1. è¯†åˆ«æ˜¯ç‰¹å®šå¸ç§æ¶ˆæ¯è¿˜æ˜¯å¸‚åœºæ•´ä½“åˆ©å¥½
2. åˆ¤æ–­äº¤æ˜“æ–¹å‘ï¼ˆåšå¤š/åšç©º/è§‚æœ›ï¼‰
3. ç»™å‡ºå…·ä½“äº¤æ˜“å‚æ•°

è¾“å‡ºæ ¼å¼ï¼ˆå¿…é¡»ä¸¥æ ¼JSONæ ¼å¼ï¼Œä½¿ç”¨ä¸­æ–‡æ ‡æ³¨ï¼‰ï¼š
{{
  "åˆ†æç»“æœ": "ç‰¹å®šå¸ç§åˆ©å¥½"æˆ–"å¸‚åœºæ•´ä½“åˆ©å¥½"æˆ–"è§‚æœ›",
  "äº¤æ˜“å¸ç§": "BTC"æˆ–["BTC","ETH","BNB","SOL"],
  "äº¤æ˜“æ–¹å‘": "long"æˆ–"short"æˆ–"è§‚æœ›",
  "æ˜¯å¦åŸºäºå›¾ç‰‡": "æ˜¯"æˆ–"å¦",
  "åˆ†æä¾æ®": "æ˜ç¡®æåŠBitcoinçªç ´å…³é”®ä»·ä½ï¼Œå¼ºçƒˆçœ‹æ¶¨ä¿¡å·",
  "é¢„æœŸæ¶ˆæ¯å¯¹å¸‚åœºè¡Œæƒ…å½±å“çš„æŒç»­æ—¶é—´":"åˆ†é’Ÿï¼Œå°æ—¶ï¼Œå¤©",
  "æ¶ˆæ¯ç½®ä¿¡åº¦":"0-100"
}}

è§„åˆ™ï¼š
- ä¸¥æ ¼è¾“å‡ºJSONæ ¼å¼
- å¸‚åœºåˆ©å¥½æ—¶äº¤æ˜“ä¸»æµå¸ç§(BTC/ETH/BNB/SOL)
- ä¿¡å·ä¸æ˜ç¡®æ—¶é€‰æ‹©è§‚æœ›
- ç‰¹å®šå¸ç§åˆ©å¥½åªäº¤æ˜“è¯¥å¸ç§
- å¸‚åœºæ•´ä½“åˆ©å¥½åŒæ—¶äº¤æ˜“å¤šä¸ªä¸»æµå¸ç§
- æ¶ˆæ¯ç½®ä¿¡åº¦ 100 ä¸º100%å¯ä¿¡
"""

    prompt = hint or ("è¯·åŸºäºä»¥ä¸‹æ¨æ–‡æ–‡æœ¬åšäº¤æ˜“ç›¸å…³æ€§ä¸æƒ…ç»ªçš„ç®€è¦åˆ†æï¼Œå¹¶ç»™å‡ºè¦ç‚¹ï¼š\n" + (text or ""))
    try:
        import openai  # å»¶è¿Ÿå¯¼å…¥
        client = openai.OpenAI(api_key=AI_API_KEY, base_url=AI_BASE_URL)
        chat = client.chat.completions.create(
            model=AI_MODEL,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
            max_tokens=500,
        )
        # å…¼å®¹ openai è¿”å›å¯¹è±¡çš„ä¸¤ç§å¯èƒ½ç»“æ„
        content: Any = None
        if chat and getattr(chat, "choices", None):
            choice0 = chat.choices[0]
            msg = getattr(choice0, "message", None)
            if isinstance(msg, dict):
                content = msg.get("content")
            else:
                content = getattr(msg, "content", None)
        return content or "(AI æ— å†…å®¹è¿”å›)"
    except Exception as e:
        return f"(AI è·³è¿‡ï¼š{e})"


# -----------------------
# å•æ¬¡è¿è¡Œï¼šfetch â†’ ä¿å­˜æœ¬åœ° â†’ ä¸¥æ ¼è¯»å– â†’ è§£æ â†’ å­˜å‚¨ â†’ é¢„è§ˆ â†’ AI
# -----------------------
def run_once(username: str = TARGET_USER, count: int = TWEET_LIMIT):
    latest_path = LOCAL_JSON_PATH
    # print("[RUN ] å¼€å§‹æ¥å£è·å–:", username)
    # raw = fetch_last_tweets(username, count)
    # time.sleep(REQUEST_INTERVAL_SEC)  # å›ºå®š5ç§’ï¼Œæ— é‡è¯•

    # ensure_media_dir()  # ç¡®ä¿ç›®å½•å­˜åœ¨
    
    # try:
    #     with open(latest_path, "w", encoding="utf-8") as f:
    #         json.dump(raw, f, ensure_ascii=False, indent=2)
    #     print("[SAVE] åŸå§‹å“åº”å·²å†™å…¥:", latest_path)
    # except Exception as e:
    #     print("[ERR ] å†™å…¥æœ¬åœ°åŸå§‹JSONå¤±è´¥:", e)
    #     # å³ä¾¿å†™å¤±è´¥ï¼Œä¹Ÿç»§ç»­å°è¯•è§£æå†…å­˜æ•°æ®



    # è°ƒè¯•æœŸï¼šä¸€å¾‹ä»æœ¬åœ° strict è¯»å–ï¼Œä¿éšœæ•°æ®ç»“æ„å¥åº·
    # try:
    #     raw_local = load_local_json_strict(latest_path)
    #     print("[INFO] æœ¬åœ°è¯»å–æ¡æ•°:", len(raw_local))
    # except Exception as e:
    #     print("[FATAL] æœ¬åœ°JSONä¸ç¬¦åˆä¸¥æ ¼ç»“æ„:", e)
    #     return {"ok": False, "error": str(e), "saved": latest_path}




    # rows = parse_tweets(raw_local)
    # ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    # parsed_json_path = os.path.join(MEDIA_DIR, f"parsed_{username}_{ts}.json")
    # parsed_csv_path = os.path.join(MEDIA_DIR, f"parsed_{username}_{ts}.csv")
    # try:
    #     save_json(parsed_json_path, rows)
    #     save_csv(parsed_csv_path, rows)
    #     print("[SAVE] è§£æç»“æœ JSON:", parsed_json_path)
    #     print("[SAVE] è§£æç»“æœ CSV :", parsed_csv_path)
    # except Exception as e:
    #     print("[ERR ] ä¿å­˜è§£æç»“æœå¤±è´¥:", e)

    # # åª’ä½“ä¸‹è½½ä¸é¢„è§ˆ
    # try:
    #     store_media_and_preview(rows, limit=3)
    # except Exception as e:
    #     print("[WARN] åª’ä½“å¤„ç†å‡ºç°é—®é¢˜:", e)

    # AI æ–‡æœ¬èšåˆä¸åˆ†æï¼ˆç®€å•æ‹¼æ¥å‰è‹¥å¹²æ¡ï¼‰
    text = """
{
      "type": "tweet",
      "id": "1988883673144336473",
      "url": "https://x.com/cz_binance/status/1988883673144336473",
      "twitterUrl": "https://twitter.com/cz_binance/status/1988883673144336473",
      "text": "Writing the book made me realize my English is poor, very poor.\n\nReviewing the Chinese translations by my colleagues made me realize my Chinese is non-existent. Had to use the dictionary constantly.\n\nBasically, I don't really speak any language. ğŸ˜‚",
      "source": "Twitter for iPhone",
      "retweetCount": 58,
      "replyCount": 820,
      "likeCount": 1217,
      "quoteCount": 24,
      "viewCount": 125890,
      "createdAt": "Thu Nov 13 08:16:34 +0000 2025",
      "lang": "en",
      "bookmarkCount": 26,
      "isReply": false,
      "inReplyToId": null,
      "conversationId": "1988883673144336473",
      "displayTextRange": [
        0,
        247
      ],
      "inReplyToUserId": null,
      "inReplyToUsername": null,
      "author": {
        "type": "user",
        "userName": "cz_binance",
        "url": "https://x.com/cz_binance",
        "twitterUrl": "https://twitter.com/cz_binance",
        "id": "902926941413453824",
        "name": "CZ ğŸ”¶ BNB",
        "isVerified": false,
        "isBlueVerified": true,
        "verifiedType": null,
        "profilePicture": "https://pbs.twimg.com/profile_images/1961440580279336960/PiiIs8Lh_normal.jpg",
        "coverPicture": "https://pbs.twimg.com/profile_banners/902926941413453824/1597864552",
        "description": "",
        "location": "",
        "followers": 10480803,
        "following": 1237,
        "status": "",
        "canDm": false,
        "canMediaTag": true,
        "createdAt": "Wed Aug 30 16:12:13 +0000 2017",
        "entities": {
          "description": {
            "urls": []
          },
          "url": {}
        },
        "fastFollowersCount": 0,
        "favouritesCount": 17541,
        "hasCustomTimelines": true,
        "isTranslator": false,
        "mediaCount": 922,
        "statusesCount": 7364,
        "withheldInCountries": [],
        "affiliatesHighlightedLabel": {},
        "possiblySensitive": false,
        "pinnedTweetIds": [
          "1981404850832494666"
        ],
        "profile_bio": {
          "description": "@BNBchain\n@YZiLabs\n@GiggleAcademy\n@binance",
          "entities": {
            "description": {
              "user_mentions": [
                {
                  "id_str": "0",
                  "indices": [
                    0,
                    9
                  ],
                  "name": "",
                  "screen_name": "BNBchain"
                },
                {
                  "id_str": "0",
                  "indices": [
                    10,
                    18
                  ],
                  "name": "",
                  "screen_name": "YZiLabs"
                },
                {
                  "id_str": "0",
                  "indices": [
                    19,
                    33
                  ],
                  "name": "",
                  "screen_name": "GiggleAcademy"
                },
                {
                  "id_str": "0",
                  "indices": [
                    34,
                    42
                  ],
                  "name": "",
                  "screen_name": "binance"
                }
              ]
            },
            "url": {
              "urls": [
                {
                  "display_url": "binance.com",
                  "expanded_url": "http://www.binance.com",
                  "indices": [
                    0,
                    23
                  ],
                  "url": "https://t.co/zlvCSBIFGA"
                }
              ]
            }
          }
        },
        "isAutomated": false,
        "automatedBy": null
      },
      "extendedEntities": {},
      "card": null,
      "place": {},
      "entities": {},
      "quoted_tweet": {
        "type": "tweet",
        "id": "1988882854378344501",
        "url": "https://x.com/ZiksMeta/status/1988882854378344501",
        "twitterUrl": "https://twitter.com/ZiksMeta/status/1988882854378344501",
        "text": "@cz_binance Will your book be available in both soft and hard copy all over the world?",
        "source": "Twitter for iPhone",
        "retweetCount": 1,
        "replyCount": 6,
        "likeCount": 19,
        "quoteCount": 1,
        "viewCount": 127694,
        "createdAt": "Thu Nov 13 08:13:18 +0000 2025",
        "lang": "en",
        "bookmarkCount": 2,
        "isReply": true,
        "inReplyToId": "1988882745989153243",
        "conversationId": "1988882745989153243",
        "displayTextRange": [
          12,
          86
        ],
        "inReplyToUserId": null,
        "inReplyToUsername": null,
        "author": {
          "type": "user",
          "userName": "ZiksMeta",
          "url": "https://x.com/ZiksMeta",
          "twitterUrl": "https://twitter.com/ZiksMeta",
          "id": "1561355648595533831",
          "name": "Liquid",
          "isVerified": false,
          "isBlueVerified": true,
          "verifiedType": null,
          "profilePicture": "https://pbs.twimg.com/profile_images/1986094531574407168/hx2qB_uW_normal.jpg",
          "coverPicture": "https://pbs.twimg.com/profile_banners/1561355648595533831/1760161471",
          "description": "",
          "location": "In Profit",
          "followers": 2565,
          "following": 2084,
          "status": "",
          "canDm": false,
          "canMediaTag": true,
          "createdAt": "Sun Aug 21 14:13:54 +0000 2022",
          "entities": {
            "description": {
              "urls": []
            },
            "url": {}
          },
          "fastFollowersCount": 0,
          "favouritesCount": 9736,
          "hasCustomTimelines": true,
          "isTranslator": false,
          "mediaCount": 301,
          "statusesCount": 8817,
          "withheldInCountries": [],
          "affiliatesHighlightedLabel": {},
          "possiblySensitive": false,
          "pinnedTweetIds": [
            "1985797692358869052"
          ],
          "profile_bio": {
            "description": "6+ years in Crypto |Web3 |MarketingğŸ“Š |Community BuilderğŸ‘·â€â™‚ï¸ |ReplyGuyğŸ‘¨â€ğŸ’» |DegenğŸ’¹  |Posts are NFA | Always DYOR",
            "entities": {
              "description": {},
              "url": {
                "urls": [
                  {
                    "display_url": "doginaldogs.com",
                    "expanded_url": "http://doginaldogs.com",
                    "indices": [
                      0,
                      23
                    ],
                    "url": "https://t.co/yGyuYFVDT5"
                  }
                ]
              }
            }
          },
          "isAutomated": false,
          "automatedBy": null
        },
        "extendedEntities": {},
        "card": null,
        "place": {},
        "entities": {
          "user_mentions": [
            {
              "id_str": "902926941413453824",
              "indices": [
                0,
                11
              ],
              "name": "CZ ğŸ”¶ BNB",
              "screen_name": "cz_binance"
            }
          ]
        },
        "quoted_tweet": null,
        "retweeted_tweet": null,
        "isLimitedReply": false,
        "article": null
      },
      "retweeted_tweet": null,
      "isLimitedReply": false,
      "article": null
    }

"""
    try:
        sample_text = text
        if sample_text.strip():
            ai_summary = ai_analyze_text(sample_text)
            print("[AI  ] æ‘˜è¦ï¼š\n", ai_summary)
        else:
            print("[AI  ] æ— æ–‡æœ¬æ ·æœ¬ï¼Œè·³è¿‡åˆ†æ")
    except Exception as e:
        print("[WARN] AI åˆ†æå¤±è´¥:", e)



if __name__ == "__main__":
    ensure_media_dir()
    result = run_once()
    print("[DONE] è¿è¡Œç»“æŸ:", result)