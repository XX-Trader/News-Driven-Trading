{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推特最小流水线（Notebook 版）\n",
    "\n",
    "流程：配置 → 获取 → 解析 → 存储+媒体预览 → AI分析 → 一键运行\n",
    "\n",
    "约束：\n",
    "- 仅使用函数与变量，不写类\n",
    "- 每个可运行代码单元尽量不超过 20 行\n",
    "- 请求间隔固定 5 秒，不做重试\n",
    "- 媒体支持 entities.media 与 includes.media\n",
    "- 使用 Poe(OpenAI兼容) API 调用 gpt-5\n",
    "\n",
    "说明：\n",
    "- 所有可修改信息均以“变量”形式集中在“配置”单元\n",
    "- 尽量保持与脚本版逻辑一致，仅改为 Notebook 组织与展示\n",
    "- 图片在 Notebook 内渲染，视频以超链接展示\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INIT] 依赖导入完成\n"
     ]
    }
   ],
   "source": [
    "{\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5,\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"name\": \"python3\",\n",
    "   \"display_name\": \"Python 3 (ipykernel)\",\n",
    "   \"language\": \"python\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"name\": \"python\",\n",
    "   \"version\": \"3.10\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"file_extension\": \".py\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"nbconvert_exporter\": \"python\"\n",
    "  }\n",
    " },\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# 推特最小流水线（Notebook 版，逐步执行）\\n\",\n",
    "    \"\\n\",\n",
    "    \"按步骤运行，每个阶段独立输出：\\n\",\n",
    "    \"1) 配置 → 2) 获取 → 3) 等待5秒 → 4) 解析 → 5) 存储(JSON/CSV) → 6) 媒体预览 → 7) AI 分析\\n\",\n",
    "    \"\\n\",\n",
    "    \"约束：函数与变量、单元尽量≤20行、固定5秒、不重试、媒体支持 entities.media 与 includes.media、Poe(OpenAI兼容) gpt-5。\\n\",\n",
    "    \"\\n\",\n",
    "    \"若看到 JSON 文本，请使用 VSCode 右上角 “Open in Notebook Editor”。\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"execution_count\": null,\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# 1) 配置（集中变量，可直接修改）\\n\",\n",
    "    \"API_KEY = \\\"new1_58fe956453e744e4844728c68ba187d4\\\"\\n\",\n",
    "    \"API_URL = \\\"https://api.twitterapi.io/twitter/user/last_tweets\\\"\\n\",\n",
    "    \"TARGET_USER = \\\"cz_binance\\\"\\n\",\n",
    "    \"TWEET_LIMIT = 1\\n\",\n",
    "    \"REQUEST_INTERVAL_SEC = 5\\n\",\n",
    "    \"MEDIA_DIR = \\\"./推特抢跑/twitter_media\\\"\\n\",\n",
    "    \"OUTPUT_DIR = \\\"./推特抢跑\\\"\\n\",\n",
    "    \"AI_API_KEY = \\\"lUOtczZXbp6emUFgvqfZC7odtwGEhBdwmIAdTlpLHzs\\\"\\n\",\n",
    "    \"AI_BASE_URL = \\\"https://api.poe.com/v1\\\"\\n\",\n",
    "    \"AI_MODEL = \\\"gpt-5\\\"\\n\",\n",
    "    \"IMAGE_PREVIEW_LIMIT = 3\\n\",\n",
    "    \"AI_SUMMARY_TOPK = 5\\n\",\n",
    "    \"print(\\\"[INIT] 配置完成\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"execution_count\": null,\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# 依赖与显示设置\\n\",\n",
    "    \"import os, json, time, csv\\n\",\n",
    "    \"from datetime import datetime\\n\",\n",
    "    \"from typing import List, Dict\\n\",\n",
    "    \"import requests\\n\",\n",
    "    \"import matplotlib, matplotlib.pyplot as plt, matplotlib.image as mpimg\\n\",\n",
    "    \"from io import BytesIO\\n\",\n",
    "    \"matplotlib.rcParams.update({\\\"figure.figsize\\\":(6,4),\\\"figure.dpi\\\":120,\\\"savefig.dpi\\\":120,\\\"axes.unicode_minus\\\":False})\\n\",\n",
    "    \"for _f in [\\\"SimHei\\\",\\\"Microsoft YaHei\\\",\\\"Arial Unicode MS\\\"]:\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        matplotlib.rcParams[\\\"font.sans-serif\\\"]=[_f]; break\\n\",\n",
    "    \"    except Exception: pass\\n\",\n",
    "    \"print(\\\"[INIT] 依赖导入完成\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"execution_count\": null,\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# 公共函数（不写类）\\n\",\n",
    "    \"def ensure_dir(path: str) -> str:\\n\",\n",
    "    \"    p = os.path.abspath(path); os.makedirs(p, exist_ok=True); return p\\n\",\n",
    "    \"\\n\",\n",
    "    \"def fetch_last_tweets(username: str, count: int) -> List[Dict]:\\n\",\n",
    "    \"    params={\\\"userName\\\":username.lstrip(\\\"@\\\"),\\\"count\\\":count}; headers={\\\"X-API-Key\\\":API_KEY}\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        resp=requests.get(API_URL,params=params,headers=headers,timeout=30)\\n\",\n",
    "    \"    except Exception as e:\\n\",\n",
    "    \"        print(\\\"[ERR ] 请求异常:\\\",e); return []\\n\",\n",
    "    \"    if resp.status_code!=200:\\n\",\n",
    "    \"        print(\\\"[ERR ] 请求失败:\\\",resp.status_code,resp.text[:200]); return []\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        data=resp.json(); return data.get(\\\"data\\\") or data.get(\\\"tweets\\\") or data.get(\\\"results\\\") or []\\n\",\n",
    "    \"    except Exception as e:\\n\",\n",
    "    \"        print(\\\"[ERR ] JSON解析失败:\\\",e); return []\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"execution_count\": null,\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def parse_tweets(raw: List[Dict]) -> List[Dict]:\\n\",\n",
    "    \"    out=[]\\n\",\n",
    "    \"    for t in raw:\\n\",\n",
    "    \"        media=[]; ents=t.get(\\\"entities\\\",{})\\n\",\n",
    "    \"        if isinstance(ents.get(\\\"media\\\"),list):\\n\",\n",
    "    \"            for m in ents[\\\"media\\\"]:\\n\",\n",
    "    \"                url=m.get(\\\"media_url\\\") or m.get(\\\"url\\\") or m.get(\\\"media_url_https\\\")\\n\",\n",
    "    \"                if url: media.append({\\\"id\\\":m.get(\\\"id\\\"),\\\"type\\\":m.get(\\\"type\\\"),\\\"url\\\":url})\\n\",\n",
    "    \"        inc=t.get(\\\"includes\\\",{})\\n\",\n",
    "    \"        if isinstance(inc.get(\\\"media\\\"),list):\\n\",\n",
    "    \"            for m in inc[\\\"media\\\"]:\\n\",\n",
    "    \"                url=m.get(\\\"url\\\") or m.get(\\\"preview_image_url\\\")\\n\",\n",
    "    \"                if url: media.append({\\\"id\\\":m.get(\\\"media_key\\\") or m.get(\\\"id\\\"),\\\"type\\\":m.get(\\\"type\\\"),\\\"url\\\":url})\\n\",\n",
    "    \"        out.append({\\\"tweet_id\\\":t.get(\\\"id\\\"),\\\"created_at\\\":t.get(\\\"created_at\\\"),\\\"text\\\":t.get(\\\"text\\\",\\\"\\\"),\\n\",\n",
    "    \"                    \\\"author\\\":t.get(\\\"author_username\\\") or t.get(\\\"author_id\\\"),\\n\",\n",
    "    \"                    \\\"permalink\\\":t.get(\\\"url\\\") or t.get(\\\"permalink\\\"),\\\"media\\\":media})\\n\",\n",
    "    \"    return out\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"execution_count\": null,\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def save_json(path: str, data: List[Dict]) -> None:\\n\",\n",
    "    \"    with open(path,\\\"w\\\",encoding=\\\"utf-8\\\") as f: json.dump(data,f,ensure_ascii=False,indent=2)\\n\",\n",
    "    \"\\n\",\n",
    "    \"def save_csv(path: str, rows: List[Dict]) -> None:\\n\",\n",
    "    \"    with open(path,\\\"w\\\",newline=\\\"\\\",encoding=\\\"utf-8\\\") as f:\\n\",\n",
    "    \"        w=csv.writer(f); w.writerow([\\\"tweet_id\\\",\\\"created_at\\\",\\\"author\\\",\\\"text\\\",\\\"permalink\\\",\\\"media_count\\\"])\\n\",\n",
    "    \"        for r in rows: w.writerow([r[\\\"tweet_id\\\"],r[\\\"created_at\\\"],r[\\\"author\\\"],r[\\\"text\\\"].replace(\\\"\\\\n\\\",\\\" \\\"),r[\\\"permalink\\\"],len(r[\\\"media\\\"])])\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"execution_count\": null,\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def preview_media(rows: List[Dict], limit: int=3) -> None:\\n\",\n",
    "    \"    shown=0\\n\",\n",
    "    \"    for r in rows:\\n\",\n",
    "    \"        for m in r.get(\\\"media\\\",[]):\\n\",\n",
    "    \"            url=m.get(\\\"url\\\"); mtype=(m.get(\\\"type\\\") or \\\"\\\").lower()\\n\",\n",
    "    \"            if not url: continue\\n\",\n",
    "    \"            if mtype in [\\\"photo\\\",\\\"image\\\"] and shown<limit:\\n\",\n",
    "    \"                try:\\n\",\n",
    "    \"                    resp=requests.get(url,timeout=15); resp.raise_for_status()\\n\",\n",
    "    \"                    img=mpimg.imread(BytesIO(resp.content)); plt.figure(figsize=(4,4))\\n\",\n",
    "    \"                    plt.imshow(img); plt.axis(\\\"off\\\"); plt.tight_layout(); plt.show(); shown+=1\\n\",\n",
    "    \"                except Exception as e: print(\\\"[WARN] 图片预览失败:\\\",e)\\n\",\n",
    "    \"            else:\\n\",\n",
    "    \"                print(f\\\"[video/media] {mtype or 'media'} -> {url}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"execution_count\": null,\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def ai_analyze_text(text: str, hint: str=\\\"\\\") -> str:\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        import openai\\n\",\n",
    "    \"        client=openai.OpenAI(api_key=AI_API_KEY, base_url=AI_BASE_URL)\\n\",\n",
    "    \"        prompt=hint or (\\\"请基于以下推文文本做交易相关性与情绪的简要分析，并给出要点：\\\\n\\\"+text)\\n\",\n",
    "    \"        chat=client.chat.completions.create(model=AI_MODEL, messages=[{\\\"role\\\":\\\"user\\\",\\\"content\\\":prompt}])\\n\",\n",
    "    \"        return chat.choices[0].message.content\\n\",\n",
    "    \"    except Exception as e:\\n\",\n",
    "    \"        print(\\\"[WARN] AI 分析失败或依赖缺失，返回占位文本。原因:\\\",e)\\n\",\n",
    "    \"        return \\\"AI 分析暂不可用（依赖缺失或请求失败）。\\\"\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2) 获取（只运行此格执行“获取”）\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"execution_count\": null,\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"raw = fetch_last_tweets(TARGET_USER, TWEET_LIMIT)\\n\",\n",
    "    \"print(\\\"[INFO] 获取条数:\\\", len(raw))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3) 固定等待 5 秒（节流）\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"execution_count\": null,\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"time.sleep(REQUEST_INTERVAL_SEC)\\n\",\n",
    "    \"print(\\\"[SLEEP] 已等待\\\", REQUEST_INTERVAL_SEC, \\\"秒\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4) 解析（只运行此格执行“解析”）\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"execution_count\": null,\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"rows = parse_tweets(raw)\\n\",\n",
    "    \"print(\\\"[INFO] 解析完成，记录数:\\\", len(rows), \\\"含媒体条数:\\\", sum(1 for r in rows if r[\\\"media\\\"]))\\n\",\n",
    "    \"print(\\\"[SAMPLE] 首条文本:\\\\n\\\", (rows[0][\\\"text\\\"] if rows else \\\"(empty)\\\"))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5) 存储（JSON 与 CSV）\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"execution_count\": null,\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"ensure_dir(OUTPUT_DIR)\\n\",\n",
    "    \"ts = datetime.now().strftime(\\\"%Y%m%d_%H%M%S\\\")\\n\",\n",
    "    \"json_path = os.path.join(OUTPUT_DIR, f\\\"tweets_{TARGET_USER}_{ts}.json\\\")\\n\",\n",
    "    \"csv_path  = os.path.join(OUTPUT_DIR, f\\\"tweets_{TARGET_USER}_{ts}.csv\\\")\\n\",\n",
    "    \"save_json(json_path, rows); save_csv(csv_path, rows)\\n\",\n",
    "    \"print(\\\"[SAVE]\\\", json_path, \\\"|\\\", csv_path)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6) 媒体预览（仅图片渲染，视频打印链接）\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"execution_count\": null,\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"ensure_dir(MEDIA_DIR)\\n\",\n",
    "    \"preview_media(rows, limit=IMAGE_PREVIEW_LIMIT)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 7) AI 分析（Poe 兼容 gpt-5）\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"execution_count\": null,\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"merged_text = \\\"\\\\n\\\\n\\\".join(r[\\\"text\\\"] for r in rows[:AI_SUMMARY_TOPK])\\n\",\n",
    "    \"summary = ai_analyze_text(merged_text)\\n\",\n",
    "    \"print(\\\"[AI ] 摘要前800字:\\\\n\\\", (summary or \\\"\\\")[:800])\"\n",
    "   ]\n",
    "  }\n",
    " ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 工具函数：仅函数与变量，不写类\n",
    "def ensure_dir(path: str) -> str:\n",
    "    p = os.path.abspath(path)\n",
    "    os.makedirs(p, exist_ok=True)\n",
    "    return p\n",
    "\n",
    "def download_file(url: str, local_path: str, timeout: int = 30) -> bool:\n",
    "    try:\n",
    "        r = requests.get(url, timeout=timeout, stream=True)\n",
    "        r.raise_for_status()\n",
    "        with open(local_path, \"wb\") as f:\n",
    "            for c in r.iter_content(8192):\n",
    "                if c:\n",
    "                    f.write(c)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(\"[WARN] 媒体下载失败:\", e)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取：固定 5 秒间隔，不做重试\n",
    "def fetch_last_tweets(username: str, count: int) -> List[Dict]:\n",
    "    params = {\"userName\": username.lstrip(\"@\"), \"count\": count}\n",
    "    headers = {\"X-API-Key\": API_KEY}\n",
    "    try:\n",
    "        resp = requests.get(API_URL, params=params, headers=headers, timeout=30)\n",
    "    except Exception as e:\n",
    "        print(\"[ERR ] 请求异常:\", e)\n",
    "        return []\n",
    "    if resp.status_code != 200:\n",
    "        print(\"[ERR ] 请求失败:\", resp.status_code, resp.text[:200])\n",
    "        return []\n",
    "    try:\n",
    "        data = resp.json()\n",
    "        return data.get(\"data\") or data.get(\"tweets\") or data.get(\"results\") or []\n",
    "    except Exception as e:\n",
    "        print(\"[ERR ] JSON解析失败:\", e)\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解析：支持 entities.media 与 includes.media\n",
    "def parse_tweets(raw: List[Dict]) -> List[Dict]:\n",
    "    out: List[Dict] = []\n",
    "    for t in raw:\n",
    "        media = []\n",
    "        ents = t.get(\"entities\", {})\n",
    "        if isinstance(ents.get(\"media\"), list):\n",
    "            for m in ents[\"media\"]:\n",
    "                url = m.get(\"media_url\") or m.get(\"url\") or m.get(\"media_url_https\")\n",
    "                if url:\n",
    "                    media.append({\"id\": m.get(\"id\"), \"type\": m.get(\"type\"), \"url\": url})\n",
    "        inc = t.get(\"includes\", {})\n",
    "        if isinstance(inc.get(\"media\"), list):\n",
    "            for m in inc[\"media\"]:\n",
    "                url = m.get(\"url\") or m.get(\"preview_image_url\")\n",
    "                if url:\n",
    "                    media.append({\"id\": m.get(\"media_key\") or m.get(\"id\"), \"type\": m.get(\"type\"), \"url\": url})\n",
    "        out.append({\n",
    "            \"tweet_id\": t.get(\"id\"),\n",
    "            \"created_at\": t.get(\"created_at\"),\n",
    "            \"text\": t.get(\"text\", \"\"),\n",
    "            \"author\": t.get(\"author_username\") or t.get(\"author_id\"),\n",
    "            \"permalink\": t.get(\"url\") or t.get(\"permalink\"),\n",
    "            \"media\": media,\n",
    "        })\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存储：JSON 与 CSV（避免超 20 行，拆成两个函数）\n",
    "def save_json(path: str, data: List[Dict]) -> None:\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def save_csv(path: str, rows: List[Dict]) -> None:\n",
    "    with open(path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([\"tweet_id\", \"created_at\", \"author\", \"text\", \"permalink\", \"media_count\"])\n",
    "        for r in rows:\n",
    "            w.writerow([\n",
    "                r[\"tweet_id\"], r[\"created_at\"], r[\"author\"],\n",
    "                r[\"text\"].replace(\"\\n\", \" \"), r[\"permalink\"], len(r[\"media\"]),\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 媒体预览（Notebook）：图片渲染，视频以链接形式展示\n",
    "def preview_media(rows: List[Dict], limit: int = 3) -> None:\n",
    "    shown = 0\n",
    "    html_parts = []\n",
    "    for r in rows:\n",
    "        for m in r[\"media\"]:\n",
    "            url = m.get(\"url\")\n",
    "            mtype = (m.get(\"type\") or \"\").lower()\n",
    "            if not url:\n",
    "                continue\n",
    "            if mtype in [\"photo\", \"image\"] and shown < limit:\n",
    "                try:\n",
    "                    resp = requests.get(url, timeout=15)\n",
    "                    resp.raise_for_status()\n",
    "                    img = Image.open(BytesIO(resp.content))\n",
    "                    display(img)\n",
    "                    shown += 1\n",
    "                except Exception as e:\n",
    "                    print(\"[WARN] 图片预览失败:\", e)\n",
    "            else:\n",
    "                html_parts.append(f\"<p>[{mtype or 'media'}] <a href='{url}' target='_blank'>链接</a></p>\")\n",
    "    if html_parts:\n",
    "        display(HTML(\"\\n\".join(html_parts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI 分析：Poe(OpenAI兼容) gpt-5；若依赖缺失或失败，返回占位文本\n",
    "def ai_analyze_text(text: str, hint: str = \"\") -> str:\n",
    "    try:\n",
    "        import openai\n",
    "        client = openai.OpenAI(api_key=AI_API_KEY, base_url=AI_BASE_URL)\n",
    "        prompt = hint or (\"请基于以下推文文本做交易相关性与情绪的简要分析，并给出要点：\\n\" + text)\n",
    "        chat = client.chat.completions.create(\n",
    "            model=AI_MODEL,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        )\n",
    "        return chat.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(\"[WARN] AI 分析失败或依赖缺失，返回占位文本。原因:\", e)\n",
    "        return \"AI 分析暂不可用（依赖缺失或请求失败）。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一次完整运行：配置 → 获取 → 等待5s → 解析 → 存储 → 预览 → AI\n",
    "def run_once(username: str, count: int) -> Dict:\n",
    "    print(\"[RUN ] 开始获取:\", username)\n",
    "    raw = fetch_last_tweets(username, count)\n",
    "    print(\"[INFO] 获取条数:\", len(raw))\n",
    "    time.sleep(REQUEST_INTERVAL_SEC)\n",
    "    rows = parse_tweets(raw)\n",
    "    print(\"[INFO] 解析完成，含媒体条数:\", sum(1 for r in rows if r[\"media\"]))\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    ensure_dir(OUTPUT_DIR)\n",
    "    json_path = os.path.join(OUTPUT_DIR, f\"tweets_{username}_{ts}.json\")\n",
    "    csv_path = os.path.join(OUTPUT_DIR, f\"tweets_{username}_{ts}.csv\")\n",
    "    save_json(json_path, rows)\n",
    "    save_csv(csv_path, rows)\n",
    "    print(\"[SAVE] 已保存:\", json_path, csv_path)\n",
    "    ensure_dir(MEDIA_DIR)\n",
    "    preview_media(rows, limit=IMAGE_PREVIEW_LIMIT)\n",
    "    merged_text = \"\\n\\n\".join(r[\"text\"] for r in rows[:AI_SUMMARY_TOPK])\n",
    "    summary = ai_analyze_text(merged_text)\n",
    "    return {\"rows\": rows, \"json\": json_path, \"csv\": csv_path, \"ai\": summary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TARGET_USER' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 一键运行（可直接执行本单元）\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m result = run_once(\u001b[43mTARGET_USER\u001b[49m, TWEET_LIMIT)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m[DONE] 完成，推文数:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(result[\u001b[33m\"\u001b[39m\u001b[33mrows\u001b[39m\u001b[33m\"\u001b[39m]))\n",
      "\u001b[31mNameError\u001b[39m: name 'TARGET_USER' is not defined"
     ]
    }
   ],
   "source": [
    "# 一键运行（可直接执行本单元）\n",
    "result = run_once(TARGET_USER, TWEET_LIMIT)\n",
    "print(\"[DONE] 完成，推文数:\", len(result[\"rows\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 展示 AI 摘要（前 800 字）\n",
    "ai_preview = (result.get(\"ai\") or \"\")[:800]\n",
    "print(\"[AI ] 摘要预览:\\n\", ai_preview)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
